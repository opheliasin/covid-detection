{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "S0UnVeBCHXYJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 04:01:19.041989: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# import necessary packages\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\" \n",
    "import pathlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# import numba\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython import display\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import librosa \n",
    "\n",
    "# Set the seed value for experiment reproducibility.\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "gsel7TEhHhc9"
   },
   "outputs": [],
   "source": [
    "audio_path = 'dataset/AUDIO_NEW/'\n",
    "audio_types = ['breathing', 'cough', 'speech']\n",
    "\n",
    "pos_directory_breathing = './dataset/AUDIO_NEW/breathing/COVID_Positive'\n",
    "neg_directory_breathing = './dataset/AUDIO_NEW/breathing/COVID_Negative'\n",
    "\n",
    "pos_directory_cough = './dataset/AUDIO_NEW/cough/COVID_Positive'\n",
    "neg_directory_cough = './dataset/AUDIO_NEW/cough/COVID_Negative'\n",
    "\n",
    "pos_directory_speech = './dataset/AUDIO_NEW/speech/COVID_Positive'\n",
    "neg_directory_speech = './dataset/AUDIO_NEW/speech/COVID_Negative'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "vc8NVOwZJwW6"
   },
   "outputs": [],
   "source": [
    "def get_directories(audio_path, audio_type):\n",
    "    pos_directory = os.path.join(audio_path, audio_type, 'COVID_Positive')\n",
    "    neg_directory = os.path.join(audio_path, audio_type, 'COVID_Negative')\n",
    "    \n",
    "    print(f\"Positive Directory: {pos_directory}\")\n",
    "    print(f\"Negative Directory: {neg_directory}\")\n",
    "    \n",
    "    return pos_directory, neg_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### breathing mel spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_directory_breathing, neg_directory_breathing = get_directories(audio_path, audio_types[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def create_mel_spectrogram(y, sr, file_path):\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=512, hop_length=128, n_mels=128)\n",
    "    log_mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "\n",
    "    # Normalize the spectrogram\n",
    "    if np.std(log_mel_spectrogram) == 0:\n",
    "        print(\"log_mel_spectrogram == 0: \", file_path.resolve())\n",
    "    # Normalize the spectrogram\n",
    "    epsilon = 1e-6  # Small value to avoid division by zero\n",
    "    log_mel_spectrogram = (log_mel_spectrogram - np.mean(log_mel_spectrogram)) / (np.std(log_mel_spectrogram) + epsilon)\n",
    "\n",
    "    # Add channel dimension\n",
    "    log_mel_spectrogram = np.expand_dims(log_mel_spectrogram, axis=-1)  \n",
    "    \n",
    "    return log_mel_spectrogram\n",
    "def create_zero_crossing_rate(y):\n",
    "    return np.mean(librosa.feature.zero_crossing_rate(y))\n",
    "def create_spectral_centroid(y, sr):\n",
    "    return np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(pos_directory, neg_directory, target_length):\n",
    "    spectrograms = []\n",
    "    other_features = []\n",
    "    labels = []\n",
    "\n",
    "    # Read positive samples\n",
    "    for file in os.listdir(pos_directory):\n",
    "        file_path = os.path.join(pos_directory, file)\n",
    "        y, sr = librosa.load(file_path, sr=22050, duration=target_length)\n",
    "        \n",
    "        if y.size == 0:\n",
    "            continue\n",
    "        \n",
    "        # Generate features\n",
    "        spectrogram = create_mel_spectrogram(y, sr, pathlib.Path(file_path))\n",
    "        zero_crossing_rate = create_zero_crossing_rate(y)\n",
    "        spectral_centroid = create_spectral_centroid(y, sr)\n",
    "        \n",
    "        # Append the features\n",
    "        spectrograms.append(spectrogram)\n",
    "        other_features.append([zero_crossing_rate, spectral_centroid])\n",
    "        labels.append(1)  # Label for positive class\n",
    "\n",
    "    # Read negative samples\n",
    "    for file in os.listdir(neg_directory):\n",
    "        file_path = os.path.join(neg_directory, file)\n",
    "        y, sr = librosa.load(file_path, sr=22050, duration=target_length)\n",
    "        if y.size == 0:\n",
    "            continue \n",
    "        # Generate features\n",
    "        spectrogram = create_mel_spectrogram(y, sr, pathlib.Path(file_path))\n",
    "        zero_crossing_rate = create_zero_crossing_rate(y)\n",
    "        spectral_centroid = create_spectral_centroid(y, sr)\n",
    "        \n",
    "        # Append the features\n",
    "        spectrograms.append(spectrogram)\n",
    "        other_features.append([zero_crossing_rate, spectral_centroid])\n",
    "        labels.append(0)  # Label for negative class\n",
    "\n",
    "    return spectrograms, other_features, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def create_features_for_all(target_length):\n",
    "    # All audio types\n",
    "    all_spectrograms = []\n",
    "    all_other_features = []\n",
    "    all_labels = []\n",
    "\n",
    "    # List of directories for each audio type\n",
    "    audio_types = ['breathing', 'cough', 'speech']\n",
    "\n",
    "    for audio_type in audio_types:\n",
    "        # Define the directories based on audio_type\n",
    "        if audio_type == 'breathing':\n",
    "            pos_directory = pos_directory_breathing\n",
    "            neg_directory = neg_directory_breathing\n",
    "        elif audio_type == 'cough':\n",
    "            pos_directory = pos_directory_cough\n",
    "            neg_directory = neg_directory_cough\n",
    "        elif audio_type == 'speech':\n",
    "            pos_directory = pos_directory_speech\n",
    "            neg_directory = neg_directory_speech\n",
    "        \n",
    "        # Generate features for the current type\n",
    "        spectrograms, other_features, labels = create_features(pos_directory, neg_directory, target_length)\n",
    "        \n",
    "        # Collect results\n",
    "        all_spectrograms.extend(spectrograms)\n",
    "        all_other_features.extend(other_features)\n",
    "        all_labels.extend(labels)\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    all_spectrograms = np.array(all_spectrograms)\n",
    "    all_other_features = np.array(all_other_features)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    return all_spectrograms, all_other_features, all_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "target_length = 80000\n",
    "spectrograms, other_features, labels = create_features_for_all(target_length)\n",
    "\n",
    "print(f\"Spectrograms: {spectrograms.shape}\")\n",
    "print(f\"Other Features: {other_features.shape}\")\n",
    "print(f\"Labels: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # List to store spectrograms and labels\n",
    "# spectrograms = []\n",
    "# zero_crossing_rates = []\n",
    "# spectral_centroids = []\n",
    "# labels = []\n",
    "\n",
    "# for file_path in pos_directory.iterdir():\n",
    "#     y, sr = librosa.load(file_path.resolve(), sr=16000)\n",
    "#     y = y[:80000]\n",
    "\n",
    "#     zero_padding = np.zeros(80000 - len(y), dtype=np.float32)\n",
    "#     y = np.concatenate([y, zero_padding],axis=0)\n",
    "    \n",
    "#     mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=512, hop_length=128, n_mels=128)\n",
    "#     log_mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "\n",
    "#     # Normalize the spectrogram\n",
    "#     log_mel_spectrogram = (log_mel_spectrogram - np.mean(log_mel_spectrogram)) / np.std(log_mel_spectrogram)\n",
    "\n",
    "#     log_mel_spectrogram = np.expand_dims(log_mel_spectrogram, axis=-1)  # Add channel dimension\n",
    "\n",
    "#     # Append to list\n",
    "#     spectrograms.append(log_mel_spectrogram)\n",
    "    \n",
    "#     zero_crossing_rate = np.mean(librosa.feature.zero_crossing_rate(y))\n",
    "#     spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))\n",
    "    \n",
    "#     zero_crossing_rates.append(zero_crossing_rate)\n",
    "#     spectral_centroids.append(spectral_centroid)\n",
    "    \n",
    "#     labels.append(1)  # Assuming binary classification\n",
    "\n",
    "# for file_path in neg_directory.iterdir():\n",
    "#     y, sr = librosa.load(file_path.resolve(), sr=16000)\n",
    "#     y = y[:80000]\n",
    "\n",
    "#     zero_padding = np.zeros(80000 - len(y), dtype=np.float32)\n",
    "#     y = np.concatenate([y, zero_padding],axis=0)\n",
    "    \n",
    "#     mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=512, hop_length=128, n_mels=128)\n",
    "#     log_mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "\n",
    "#     if np.std(log_mel_spectrogram) == 0:\n",
    "#         print(file_path.resolve())\n",
    "#     # Normalize the spectrogram\n",
    "#     epsilon = 1e-6  # Small value to avoid division by zero\n",
    "#     log_mel_spectrogram = (log_mel_spectrogram - np.mean(log_mel_spectrogram)) / (np.std(log_mel_spectrogram) + epsilon)\n",
    "    \n",
    "#     log_mel_spectrogram = np.expand_dims(log_mel_spectrogram, axis=-1)  # Add channel dimension\n",
    "#     #print(log_mel_spectrogram.shape)\n",
    "#     # Append to list\n",
    "#     spectrograms.append(log_mel_spectrogram)\n",
    "\n",
    "#     zero_crossing_rate = np.mean(librosa.feature.zero_crossing_rate(y))\n",
    "#     spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))\n",
    "    \n",
    "#     zero_crossing_rates.append(zero_crossing_rate)\n",
    "#     spectral_centroids.append(spectral_centroid)\n",
    "    \n",
    "#     labels.append(0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrograms = np.array(spectrograms)\n",
    "other_features = np.array(other_features)\n",
    "spectrograms_flattened = spectrograms.reshape(spectrograms.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrograms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrograms_flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_combined = np.hstack([spectrograms_flattened, other_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, labels, test_size=0.2, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_combined[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Flatten each spectrogram into a single vector\n",
    "# Resulting shape will be (num_samples, height * width * channels)\n",
    "# X_train_numpy = np.array(X_train)\n",
    "# X_train_flattened = X_train_numpy.reshape(X_train_numpy.shape[0], -1)\n",
    "\n",
    "# print(f\"Original shape: {X_train_numpy.shape}\")\n",
    "# print(f\"Flattened shape: {X_train_flattened.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "from collections import Counter\n",
    "\n",
    "smote_enn = SMOTEENN(random_state=seed)\n",
    "X_train_resampled, y_train_resampled = smote_enn.fit_resample(X_train, y_train)\n",
    "\n",
    "# Print resampled class distribution\n",
    "print(f\"Resampled class distribution: {Counter(y_train_resampled)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# from imblearn.combine import SMOTEENN\n",
    "# from collections import Counter\n",
    "\n",
    "# smote_enn = SMOTEENN(random_state=seed)\n",
    "# X_resampled, y_resampled = smote_enn.fit_resample(X_train_flattened, y_train)\n",
    "\n",
    "# # Print resampled class distribution\n",
    "# print(f\"Resampled class distribution: {Counter(y_resampled)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # Reshape back to original format after resampling\n",
    "# X_resampled = X_resampled.reshape(X_resampled.shape[0], 128, 626, 1)\n",
    "\n",
    "# print(f\"Reshaped back to original format: {X_resampled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_spectrogram_features = 128 * 626  # Flattened size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate resampled spectrograms and other features for X_train_resampled\n",
    "spectrograms_resampled = X_train_resampled[:, :num_spectrogram_features]\n",
    "other_features_resampled = X_train_resampled[:, num_spectrogram_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrograms_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the flattened spectrograms back to their original shape (128x626)\n",
    "spectrograms_resampled_reshaped = spectrograms_resampled.reshape(spectrograms_resampled.shape[0], 128, 626, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally add a channel dimension for CNN input (e.g., shape: [samples, 128, 626, 1])\n",
    "#spectrograms_resampled_reshaped = np.expand_dims(spectrograms_resampled_reshaped, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrograms_resampled_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_features_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "\n",
    "# Function to plot spectrogram\n",
    "def plot_spectrogram(spectrogram, title):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    # Remove channel dimension if present for visualization\n",
    "    if spectrogram.shape[-1] == 1:\n",
    "        spectrogram = spectrogram.squeeze(-1)\n",
    "    librosa.display.specshow(spectrogram.T, sr=22050, x_axis='time', y_axis='mel')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Assuming 'original_spectrogram' is your original unflattened spectrogram\n",
    "# and 'reshaped_spectrogram' is your reshaped version after processing\n",
    "\n",
    "# Plot original spectrogram (before flattening)\n",
    "plot_spectrogram(spectrograms[0], \"Original Spectrogram\")\n",
    "\n",
    "# Plot reshaped spectrogram (after reshaping back)\n",
    "plot_spectrogram(spectrograms_resampled_reshaped[100], \"Reshaped Spectrogram\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For X_test (no resampling needed), separate and reshape the spectrograms\n",
    "spectrograms_test = X_test[:, :num_spectrogram_features]\n",
    "other_features_test = X_test[:, num_spectrogram_features:]\n",
    "spectrograms_test_reshaped = spectrograms_test.reshape(spectrograms_test.shape[0], 128, 626, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_resampled = np.array(y_train_resampled)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_resampled = np.array(y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Single input model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(625,128,1)))\n",
    "\n",
    "# First Conv2D layer followed by MaxPooling\n",
    "model.add(Conv2D(16, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2))) # Reduces spatial dimensions by half\n",
    "\n",
    "# Second Conv2D layer followed by MaxPooling\n",
    "model.add(Conv2D(16, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2))) # Further reduces spatial dimensions\n",
    "\n",
    "# Third Conv2D layer followed by MaxPooling\n",
    "model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2))) # Further reduces spatial dimensions\n",
    "\n",
    "# Fourth Conv2D layer followed by MaxPooling (new)\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2))) # Further reduces spatial dimensions\n",
    "\n",
    "# Flatten and Dense layers\n",
    "#model.add(Flatten())\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('Adam', loss='BinaryCrossentropy', metrics=[tf.keras.metrics.Recall(),tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist = model.fit(X_train_resampled, y_train_resampled, batch_size = 16, verbose = 2, epochs=20, validation_split = 0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Fit Model, View Loss and KPI Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_binary = (y_pred > 0.99).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(y_test, y_pred_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay(cm)\n",
    "\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-input model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense, Concatenate, Dropout\n",
    "\n",
    "# Define input for Mel spectrogram (shape: 625 time frames x 128 frequency bins x 1 channel)\n",
    "mel_input = Input(shape=(128, 626, 1), name='mel_spectrogram')\n",
    "\n",
    "# Define CNN sub-network for Mel spectrogram\n",
    "x = Conv2D(16, (3,3), activation='relu')(mel_input)\n",
    "x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "x = Conv2D(16, (3,3), activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "x = Conv2D(32, (3,3), activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "x = Conv2D(64, (3,3), activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Define input for other features (e.g., zero-crossing rate and spectral centroid)\n",
    "other_input = Input(shape=(2,), name='other_features')\n",
    "\n",
    "# Define a simple dense sub-network for other features\n",
    "y = Dense(64, activation='relu')(other_input)\n",
    "y = Dense(128, activation='relu')(y)  # Add more dense layers\n",
    "y = Dropout(0.3)(y)                   # Add dropout to prevent overfitting\n",
    "y = Dense(128, activation='relu')(y)   # Another dense layer\n",
    "y = Dense(64, activation='relu')(y)    # Another dense layer\n",
    "\n",
    "# Concatenate both sub-networks\n",
    "combined = Concatenate()([x, y])\n",
    "\n",
    "# Add final classification layers\n",
    "z = Dense(128, activation='relu')(combined)\n",
    "z = Dense(1, activation='sigmoid')(z)  # Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_spectrograms = spectrograms_resampled_reshaped\n",
    "X_train_others = other_features_resampled\n",
    "y_train = y_train_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model with two inputs\n",
    "model = tf.keras.Model(inputs=[mel_input, other_input], outputs=z)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy','recall','precision'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    [X_train_spectrograms,\n",
    "     X_train_others],\n",
    "    y_train,\n",
    "    validation_split = 0.1,\n",
    "    verbose = 2,\n",
    "    epochs=20,\n",
    "    batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_spectrograms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_train = model.predict([X_train_spectrograms, X_train_others])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train_binary = (y_pred_train > 0.99).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_train, y_pred_train_binary)\n",
    "\n",
    "# Step 4: Visualize or print the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix for Training Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = model.predict([spectrograms_test_reshaped, other_features_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_binary = (y_pred > 0.99).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(y_test, y_pred_test_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay(cm)\n",
    "\n",
    "disp.plot()\n",
    "plt.title(\"Confusion Matrix for Testing Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
